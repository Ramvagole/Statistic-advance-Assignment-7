{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f2095-0d1f-42a4-bf06-2da655d55f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1):-\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "def variance_ratio_test(data1, data2):\n",
    "    f_value, p_value = f_oneway(data1, data2)\n",
    "    return f_value, p_value\n",
    "data1 = [1, 2, 3, 4, 5]\n",
    "data2 = [2, 4, 6, 8, 10]\n",
    "\n",
    "f_value, p_value = variance_ratio_test(data1, data2)\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d8c1f-ac4f-4999-b479-17162428de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2):-\n",
    "from scipy.stats import f\n",
    "\n",
    "def critical_f_value(alpha, dfn, dfd):\n",
    "    tail_prob = (1 - alpha) / 2 \n",
    "    critical_value = f.ppf(1 - tail_prob, dfn, dfd)\n",
    "    return critical_value\n",
    "alpha = 0.05\n",
    "dfn = 3\n",
    "dfd = 10\n",
    "\n",
    "critical_value = critical_f_value(alpha, dfn, dfd)\n",
    "print(\"Critical F-value:\", critical_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e3580-3f03-4e6d-93de-260733420475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3);-\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "def f_test_equal_variances(sample_size1, sample_size2, variance1, variance2):\n",
    "    sample1 = np.random.normal(0, np.sqrt(variance1), sample_size1)\n",
    "    sample2 = np.random.normal(0, np.sqrt(variance2), sample_size2)\n",
    "    \n",
    "    f_value, p_value = f_oneway(sample1, sample2)\n",
    "    \n",
    "    dfn = sample_size1 - 1\n",
    "    dfd = sample_size2 - 1\n",
    "    \n",
    "    return f_value, dfn, dfd, p_value\n",
    "\n",
    "sample_size1 = 100\n",
    "sample_size2 = 100\n",
    "variance1 = 4\n",
    "variance2 = 9\n",
    "\n",
    "f_value, dfn, dfd, p_value = f_test_equal_variances(sample_size1, sample_size2, variance1, variance2)\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"Degrees of Freedom (numerator):\", dfn)\n",
    "print(\"Degrees of Freedom (denominator):\", dfd)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08bb3d5-6c98-438e-ba48-f4f4c3706986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4):-\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test(variance1, variance2, sample_size1, sample_size2, alpha):\n",
    "    f_value = variance1 / variance2\n",
    "\n",
    "    dfn = sample_size1 - 1\n",
    "    dfd = sample_size2 - 1\n",
    "    \n",
    "    critical_f = f.ppf(1 - alpha / 2, dfn, dfd)\n",
    "    \n",
    "    p_value = 2 * (1 - f.cdf(f_value, dfn, dfd))\n",
    "    \n",
    "    return f_value, dfn, dfd, critical_f, p_value\n",
    "\n",
    "variance1 = 10\n",
    "variance2 = 15\n",
    "sample_size1 = 12\n",
    "sample_size2 = 12\n",
    "alpha = 0.05\n",
    "\n",
    "f_value, dfn, dfd, critical_f, p_value = f_test(variance1, variance2, sample_size1, sample_size2, alpha)\n",
    "\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"Degrees of Freedom (numerator):\", dfn)\n",
    "print(\"Degrees of Freedom (denominator):\", dfd)\n",
    "print(\"Critical F-value:\", critical_f)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if f_value > critical_f:\n",
    "    print(\"Reject null hypothesis: Variances are significantly different\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: Variances are not significantly different\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74921db3-9e4d-4347-9649-9f08fcabd063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5):-\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test(claimed_variance, sample_variance, sample_size, alpha):\n",
    "    f_value = sample_variance / claimed_variance\n",
    "    \n",
    "    dfn = sample_size - 1\n",
    "    dfd = 1\n",
    "    \n",
    "    critical_f = f.ppf(1 - alpha, dfn, dfd)\n",
    "    \n",
    "    p_value = 1 - f.cdf(f_value, dfn, dfd)\n",
    "    \n",
    "    return f_value, dfn, dfd, critical_f, p_value\n",
    "\n",
    "claimed_variance = 0.005\n",
    "sample_variance = 0.006\n",
    "sample_size = 25\n",
    "alpha = 0.01\n",
    "\n",
    "f_value, dfn, dfd, critical_f, p_value = f_test(claimed_variance, sample_variance, sample_size, alpha)\n",
    "\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"Degrees of Freedom (numerator):\", dfn)\n",
    "print(\"Degrees of Freedom (denominator):\", dfd)\n",
    "print(\"Critical F-value:\", critical_f)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if f_value > critical_f:\n",
    "    print(\"Reject null hypothesis: Claim is not justified\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: Claim is justified\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b0d52-0c3b-4785-a98d-914b30595b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6):-\n",
    "def f_distribution_mean_variance(dfn, dfd):\n",
    "    if dfd > 2:\n",
    "        mean = dfd / (dfd - 2)\n",
    "    else:\n",
    "        mean = float('inf')\n",
    "    \n",
    "    if dfd > 4:\n",
    "        variance = (2 * (dfd**2) * (dfn + dfd - 2)) / (dfn * (dfd - 2)**2 * (dfd - 4))\n",
    "    else:\n",
    "        variance = float('inf')\n",
    "    \n",
    "    return mean, variance\n",
    "dfn = 3\n",
    "dfd = 10\n",
    "\n",
    "mean, variance = f_distribution_mean_variance(dfn, dfd)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Variance:\", variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e54983-f6a0-4998-be89-bcd97e21fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7):-\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test(sample_variance1, sample_variance2, sample_size1, sample_size2, alpha):\n",
    "    f_value = sample_variance1 / sample_variance2\n",
    "    \n",
    "    dfn = sample_size1 - 1\n",
    "    dfd = sample_size2 - 1\n",
    "    \n",
    "    critical_f = f.ppf(1 - alpha, dfn, dfd)\n",
    "    \n",
    "    p_value = 1 - f.cdf(f_value, dfn, dfd)\n",
    "    \n",
    "    return f_value, dfn, dfd, critical_f, p_value\n",
    "\n",
    "sample_variance1 = 25\n",
    "sample_variance2 = 20\n",
    "sample_size1 = 10\n",
    "sample_size2 = 15\n",
    "alpha = 0.1\n",
    "\n",
    "f_value, dfn, dfd, critical_f, p_value = f_test(sample_variance1, sample_variance2, sample_size1, sample_size2, alpha)\n",
    "\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"Degrees of Freedom (numerator):\", dfn)\n",
    "print(\"Degrees of Freedom (denominator):\", dfd)\n",
    "print(\"Critical F-value:\", critical_f)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if f_value > critical_f:\n",
    "    print(\"Reject null hypothesis: Variances are not equal\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: Variances are equal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07564eed-4c3b-43ea-90eb-ae4e8b04d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8):-\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test(waiting_times1, waiting_times2, alpha):\n",
    "    sample_variance1 = np.var(waiting_times1, ddof=1)\n",
    "    sample_variance2 = np.var(waiting_times2, ddof=1)\n",
    "    \n",
    "    f_value = sample_variance1 / sample_variance2\n",
    "    \n",
    "    dfn = len(waiting_times1) - 1\n",
    "    dfd = len(waiting_times2) - 1\n",
    "    \n",
    "    critical_f = f.ppf(1 - alpha, dfn, dfd)\n",
    "    \n",
    "    p_value = 1 - f.cdf(f_value, dfn, dfd)\n",
    "    \n",
    "    return f_value, dfn, dfd, critical_f, p_value\n",
    "\n",
    "waiting_times1 = [24, 25, 28, 23, 22, 20, 27]\n",
    "waiting_times2 = [31, 33, 35, 30, 32, 36]\n",
    "alpha = 0.05\n",
    "\n",
    "f_value, dfn, dfd, critical_f, p_value = f_test(waiting_times1, waiting_times2, alpha)\n",
    "\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"Degrees of Freedom (numerator):\", dfn)\n",
    "print(\"Degrees of Freedom (denominator):\", dfd)\n",
    "print(\"Critical F-value:\", critical_f)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if f_value > critical_f:\n",
    "    print(\"Reject null hypothesis: Variances are not equal\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: Variances are equal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0646c0-58aa-41a8-839a-5da0a0227c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9):-\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test(test_scores1, test_scores2, alpha):\n",
    "    sample_variance1 = np.var(test_scores1, ddof=1)\n",
    "    sample_variance2 = np.var(test_scores2, ddof=1)\n",
    "    \n",
    "    f_value = sample_variance1 / sample_variance2\n",
    "    \n",
    "    dfn = len(test_scores1) - 1\n",
    "    dfd = len(test_scores2) - 1\n",
    "    \n",
    "    critical_f = f.ppf(1 - alpha, dfn, dfd)\n",
    "    \n",
    "    p_value = 1 - f.cdf(f_value, dfn, dfd)\n",
    "    \n",
    "    return f_value, dfn, dfd, critical_f, p_value\n",
    "\n",
    "test_scores1 = [80, 85, 90, 92, 87, 83]\n",
    "test_scores2 = [75, 78, 82, 79, 81, 84]\n",
    "alpha = 0.01\n",
    "\n",
    "f_value, dfn, dfd, critical_f, p_value = f_test(test_scores1, test_scores2, alpha)\n",
    "\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"Degrees of Freedom (numerator):\", dfn)\n",
    "print(\"Degrees of Freedom (denominator):\", dfd)\n",
    "print(\"Critical F-value:\", critical_f)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if f_value > critical_f:\n",
    "    print(\"Reject null hypothesis: Variances are not equal\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: Variances are equal\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
